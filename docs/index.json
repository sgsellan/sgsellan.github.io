[{"categories":null,"content":"Over the past three years, I have been learning more and more about using Blender to generate results for academic papers in Computer Graphics. At the same time, I have been sharing what I have learned in different venues and formats: internally with my colleagues, as aP course, as a text guide, a video or an interactive tutorial. As of July 2023, the last version of this was my 3-hour workshop at Graphics Interface 2023 in Victoria, Canada. In preparing for this workshop, I updated, reformatted and extended my previous publicaly available guides and combined them into a single course. ","date":"2023-05-29","objectID":"/blender_course.html:0:0","tags":null,"title":"Blender for Academic Papers","uri":"/blender_course.html"},{"categories":null,"content":"Full, updated course The course has three parts that you can access here in text format: Rendering a static figure using the Blender GUI Rendering an animation using the Blender GUI Rendering static figures and animations using Blender scripts ","date":"2023-05-29","objectID":"/blender_course.html:1:0","tags":null,"title":"Blender for Academic Papers","uri":"/blender_course.html"},{"categories":null,"content":"Previous editions In 2022, I gave an earlier version of this tutorial as a video course at the Symposium on Geometry Processing (SGP) Graduate School, which you can watch here. Also in 2022, a text version of my static-figure-rendering tutorial was published by the SIGGRAPH Research Carreer Development Committee, which you can access here. ","date":"2023-05-29","objectID":"/blender_course.html:2:0","tags":null,"title":"Blender for Academic Papers","uri":"/blender_course.html"},{"categories":null,"content":"Other Here’s a note about a common bug that occurse when upgrading from Blender 2.9 to 3.0. ","date":"2023-05-29","objectID":"/blender_course.html:3:0","tags":null,"title":"Blender for Academic Papers","uri":"/blender_course.html"},{"categories":null,"content":"I recently came accross this great paper by Tatsuya Amano and colleagues on the effects that being a non-native English speaker can have on one’s scientific success. It is a good exploratory study of a topic I have unfortunately thought about often, and I recommend reading it in full. Unfortunately, the authors have suffered the misfortune of being featured in this Phys.org article (which, to be fair to Phys.org, seems to come from a PLOS Biology press release), which states the following: Papers written by non-native English speakers are 2.5 times more likely to be rejected and 12.5 times more likely to receive a request for revision, simply due to the written English. Wow! This is a very surprising statement. People who don’t speak English as a first language are more than twice as likely to be rejected from scientific journals? What an extraoirdinary claim. So extraordinary, in fact, that anyone’s skepticism should be awoken by it. Is this actually what the scientists found? Let’s look at the paper: Non-native English speakers, especially those of low English proficiency nationalities, are more likely to have their papers rejected by journals due to English writing Aha! This makes more sense. Of all reasons to reject a paper, (a relatively uncommon) one is the quality of the English writing (for example, if it is hard to understand what the paper’s scientific contributions are), and non-native English speakers are more likely to have a paper rejected for this reason. This does not sound like such a surprising statistic anymore! The claim about revision requests is similarly disproven (emphasis mine): For example, 42.5% and 42.6% of the non-native English speakers of moderate and low English proficiency nationalities, respectively, compared to only 3.4% of the native English speaker population, report that they are often/most of the time/always requested to improve their English writing during paper revision. This equates to a 12.5 times higher frequency of language-related revisions for non-native English speakers. In other words, the paper is not claiming that non-native-English-speaker-written papers are more likely to be requested a revision; rather, than when they are asked to, they are more often at the same time requested to improve their English writing. Once again, probably not that surprising either (I say as a non-native-English-speaker who has often gotten this review comment before). In other words, what were two somewhat expected observations become, when filtered through the eyes of irresponsible scientific communication (be it by Phys Org or whoever provided this text to them), two outrageously false facts that can be repeated to drive engagement on the Internet. The system works! P.S.: Don’t worry, it’s fact checked and proofread! ","date":"2023-05-29","objectID":"/bad-comma.html:0:0","tags":null,"title":"On how important a comma (and responsible scientific communication) can be","uri":"/bad-comma.html"},{"categories":null,"content":"Gpytoolbox version 0.1.0 has just been released!! You can install it directly through pip: pip install gpytoolbox Gpytoolbox shines when it comes to letting you test out your research ideas on simple 2D geometry before you commit to more complex three-dimensional examples and elaborately optimized implementations. Often, our final algorithm will use triangle meshes to represent surfaces in 3D. This means that, when prototyping in 2D, we will work with its equivalent: curves built by connecting flat segments (edges), which are usually called polylines. In code, polylines are often represented by a matrix of sorted vertex coordinates $V\\in\\mathbb{R}^{n\\times 2}$. Each row contains the coordinates of a single vertex $v_i$, and the $i$-th edge is obtained by connecting the $i$-th vertex to the $i+1$-th vertex. To make a simple polyline of a circle, gpytoolbox provides a simple wrapper: import numpy as np from gpytoolbox import regular_circle_polyline vertices, _ = regular_circle_polyline(20) # 20 vertices # We can plot our polyline using matplotlib import matplotlib.pyplot as plt _ = plt.plot(vertices[:, 0], vertices[:, 1], 'o-') _ = plt.axis('equal') …but circles are a very special class of shapes, which are very simple and have a high degree of symmetry. Also, they are very boring to look at. We can get more interesting geometry by using my favourite Gpytoolbox function, png2poly, which reads polylines from .png files you can draw yourself or download from the internet. For example, I drew this picture on Adobe Illustrator. I can easily load it into Python using png2poly. from gpytoolbox import png2poly poly = png2poly(\"illustrator.png\") poly now contains a list with every connected polyline in the png file. In our case, this list has four entries: print(len(poly)) 4 This may seem counterintuitive, but it makes sense if you think about it for a bit. Since the lines in our png file are so thick, png2poly is duplicating them: it finds one line for the transition from white to red and another one for the one from red to white; then again for white to blue and blue to white. We can visualize all of them: plt.plot(poly[0][:, 0], poly[0][:, 1], '-') plt.plot(poly[1][:, 0], poly[1][:, 1], '-') plt.plot(poly[2][:, 0], poly[2][:, 1], '-') plt.plot(poly[3][:, 0], poly[3][:, 1], '-') _ = plt.axis('equal') Often, we are interested in only one of these components, so let’s just make our vertex matrix be the first entry in the list: vertices = poly[0] _ = plt.plot(vertices[:, 0], vertices[:, 1], '-') _ = plt.axis('equal') A really rich source of interesting 2D geometry that I really like to use is maps. For example, in many of my papers you’ll find this Vietnam polyline that comes from this png file: poly = png2poly(\"vietnam.png\") plt.plot(poly[0][:, 0], poly[0][:, 1], '-b') plt.plot(poly[1][:, 0], poly[1][:, 1], '-b') _ = plt.axis('equal') You might be wondering: what happens if I want a shape with more than one connected component? For example, consider this map of Hawaii: poly = png2poly(\"hawaii.png\") print(\"There are \", str(len(poly)), \" connected polylines in the image.\") # We can plot them in a loop for i in range(len(poly)): plt.plot(poly[i][:, 0], poly[i][:, 1], '-') _ = plt.axis('equal') There are 8 connected polylines in the image. To combine all the islands into a single polyline, we can can concatenate all the vertices and use an edge list EC that stores which vertices are connected. For a single connected component, this edge list is simple: the first vertex connects to the second vertex, the second vertex connects to the third, etc. # Consider the first island first_island_vertices = poly[0] # Edge indices from gpytoolbox import edge_indices first_island_edges = edge_indices(first_island_vertices.shape[0], closed=True) # The 'closed' argument tells the function to connect the last vertex to the first one print(first_island_edges) [[ 0 1] [ 1 2] [ 2 3] [ 3 4] [ 4 5] [ 5 6] [ 6 7] [ 7 8] [ 8 9] [ 9 10] [ 10 11] [ 11 12] [ 12 13] [","date":"2023-03-04","objectID":"/gpytoolbox-2d-prototyping.html:0:0","tags":null,"title":"Quick 2D prototyping with Gpytoolbox I: Generating 2D polylines ","uri":"/gpytoolbox-2d-prototyping.html"},{"categories":null,"content":"Gpytoolbox version 0.1.0 has just been released!! You can install it directly through pip: pip install gpytoolbox This is the second in a series of blogposts highlighting features of our newly released library. You can find rest of the blog entries here. Today, we are looking at how to compute distances to 2D polylines. In the last tutorial, we saw how to load simple two-dimensional polylines into Python using gpytoolbox to quickly test our research code on. The reason for using polylines as a shape representation is that they are the 2D equivalent to the very common 3D representation of triangle meshes. However, meshes are not the only way we represent geometry. In the next tutorials, we will see how to convert our 2D polylines into other representations. One very common shape representation is point clouds, or unordered sets of points in space. This is the format in which most real-world geometry is captured; for example, by the scanner on an autonomous car. If we are testing a research idea that will work on point clouds, we may want a good way of generating 2D point clouds. We can do this by sampling random points on a polyline using Gpytoolbox’s random_points_on_mesh: # Let's begin by loading the image into a polyline from gpytoolbox import png2poly, edge_indices poly = png2poly(\"switzerland.png\") vertices = poly[0] edges = edge_indices(vertices.shape[0], closed=True) _ = plt.plot(vertices[:, 0], vertices[:, 1], '-k') _ = plt.axis('equal') # Now, call random_points_on_mesh to generate a point cloud from gpytoolbox import random_points_on_mesh point_cloud = random_points_on_mesh(vertices, edges, 100) _ = plt.plot(point_cloud[:, 0], point_cloud[:, 1], 'o') Et voilà! A beautifully neutral point cloud. For some applications, we may not be content with a point cloud; instead, we may want to generate an oriented point cloud where each point is also endowed with a direction perpendicular to the surface at that point. This is also an easy representation to get using gpytoolbox: since all the points fall on some flat edge, we need only know which edge and rotate it by ninety degrees. This is what the return_indices parameter in random_points_on_mesh is for: point_cloud, I, _ = random_points_on_mesh(vertices, edges, 100, return_indices=True) # What are the edges that the points are on? edge_vectors = vertices[edges[I,0],:] - vertices[edges[I,1],:] # Rotate the edge vectors by 90 degrees edge_vectors = np.array([[-edge_vectors[:,1], edge_vectors[:,0]]]).squeeze().T # Normalize the edge vectors so they have unit norm normal_vectors = edge_vectors / np.linalg.norm(edge_vectors, axis=1)[:,None] # Plot the point cloud and normals _ = plt.plot(point_cloud[:, 0], point_cloud[:, 1], 'o') _ = plt.quiver(point_cloud[:, 0], point_cloud[:, 1], normal_vectors[:,0], normal_vectors[:,1],) ","date":"2023-03-04","objectID":"/gpytoolbox-2d-prototyping-2.html:0:0","tags":null,"title":"Quick 2D prototyping with Gpytoolbox II: Sampling 2D polylines","uri":"/gpytoolbox-2d-prototyping-2.html"},{"categories":null,"content":"Gpytoolbox version 0.1.0 has just been released!! You can install it directly through pip: pip install gpytoolbox This is the third in a series of blogposts highlighting features of our newly released library. You can find rest of the blog entries here. Today, we are looking at how to compute distances to 2D polylines. There are many reasons why you may want to compute the minimum distance from a given point in 2D to a polyline: for example, to guide sampling or as a stopping criterion in iterative algorithms. Gpytoolbox provides a breadth of tools for computing distances to fit different needs. Let’s start by loading a polyline and computing a single point’s distance to it: # load polyline from gpytoolbox import png2poly, edge_indices poly = png2poly(\"illustrator.png\") vertices = poly[0] # Downsample the polyline for simplicity vertices = vertices[::10,:] edges = edge_indices(vertices.shape[0], closed=True) import matplotlib.pyplot as plt _ = plt.plot(vertices[:, 0], vertices[:, 1], '-k') _ = plt.axis('equal') # Consider a poing in space point = np.array([200,100]) # Visualize it _ = plt.plot(point[0], point[1], 'o') _ = plt.plot(vertices[:, 0], vertices[:, 1], '-k') _ = plt.axis('equal') # Now, we call the function that computes its squared distance to the polyline from gpytoolbox import squared_distance sqrd, ind, t = squared_distance(point, vertices, F=edges) print(\"The distance is \", float(np.sqrt(sqrd))) The distance is 6.1621198369606835 squared_distance not only returns the value of the distance, it also includes very useful information. For example, it tells us the polyline edge that is the closest to our point: # Plot the polyline and the closest edge _ = plt.plot(vertices[:, 0], vertices[:, 1], '-k') # Get the vertices of the closest edge vertices_of_closest_edge = vertices[edges[ind,:],:].squeeze() _ = plt.plot(vertices_of_closest_edge[:,0], vertices_of_closest_edge[:,1], '-r', linewidth=3) _ = plt.plot(point[0], point[1], 'o') _ = plt.axis('equal') It also includes a parameter t, that tells us where along that edge the closest polyline point lays. We can use it to calculate said closest point: # Find the closest point on the polyline closest_point = vertices[edges[ind,0],:] + (1-t) * (vertices[edges[ind,1],:] - vertices[edges[ind,0],:]) closest_point = closest_point.squeeze() print(\"The closest point is \", closest_point) # Plot the polyline and the closest point _ = plt.plot(vertices[:, 0], vertices[:, 1], '-k') _ = plt.plot(point[0], point[1], 'o') _ = plt.plot(vertices_of_closest_edge[:,0], vertices_of_closest_edge[:,1], '-r', linewidth=3) _ = plt.plot(closest_point[0], closest_point[1], 'o') _ = plt.axis('equal') The closest point is [200.97159662 105.31480424] Using squared_distance we can find the distance of many points to the polyline at the same time: # Often, it helps to normalize the polyline from gpytoolbox import normalize_points vertices = normalize_points(vertices) # Generate many random points points = np.random.rand(1000,2)-0.5 # Compute the squared distance to the polyline sqrd, ind, t = squared_distance(points, vertices, F=edges) # Plot the polyline and the points _ = plt.plot(vertices[:, 0], vertices[:, 1], '-k') # Plot points with sqrd as color _ = plt.scatter(points[:,0], points[:,1], c=sqrd) _ = plt.colorbar() _ = plt.axis('equal') You may have noticed that computation took some time. That’s because, for each point in the set, squared_distance is going through every single edge in the polyline to check if it’s the closest. This performance hit will be significant, especially if the shape is very complex: # Let's begin by loading the image into a polyline from gpytoolbox import png2poly, edge_indices poly = png2poly(\"switzerland.png\") vertices = poly[0] # Normalize the polyline vertices = normalize_points(vertices) edges = edge_indices(vertices.shape[0]) # Compute the squared distance to the polyline sqrd, ind, t = squared_distance(points, vertices, F=edges) # Plot the polyline and the points ","date":"2023-03-04","objectID":"/gpytoolbox-2d-prototyping-3.html:0:0","tags":null,"title":"Quick 2D prototyping with Gpytoolbox III: Distances to 2D polylines","uri":"/gpytoolbox-2d-prototyping-3.html"},{"categories":null,"content":"Introduction: showing scripting screen in GUI Let’s open any Blender file, like our template file, and let’s fine-tune it a little bit; for example, by changing the main object’s position. We can now navigate to the scripting window by clicking on the top right, next to compositing, to find something like this If we look closely at the console of the left, we can see a history of all the recent commands that have been applied to this file through its user interface. In this case, we see one command that corresponds to moving the main object in the scene. Of course, as computer scientists, it may not be surprising for us to see that all the actions we take in Blender’s graphical interface correspond to executing specific programatic commands. However, what is special about Blender is that these commands are in an accessible, readable programming language (python) and they are exposed such that anyone can learn them and write their own Blender scripts. This option is most attractive to us as academics: often, we want to render two objects with the exact same rendering setup (e.g., for a comparison) or we may want to update a paper figures after a chage in our method by simply re-running a script, without having to resort to hours of GUI manipulation. Blender toolbox, clone The best way to start scripting on Blender is with the help of Hsueh-Ti Derek Liu’s own Blender toolbox. We can clone it by running git clone https://github.com/HTDerekLiu/BlenderToolbox.git Some of the aspects of this tutorial will rely on specific hardcoded paths, so let us from now on assume that our directory structure looks like this for some master directory dir: dir/ └── BlenderToolbox/ First steps: imports and initialize scene, saving file To start writing our first Blender script, we will create a new file called render.py and store it in dir: dir/ └── BlenderToolbox/ └── render.py Our file render.py will start with some basic library imports (tip: watch out for the differences in capitalization of “toolbox”). import sys, os, bpy, bmesh import numpy as np this_file_path = os.path.dirname(__file__) sys.path.append(os.path.join(this_file_path,'BlenderToolbox')) import BlenderToolBox as bt We can now validate that our library import works by executing render.py. A common mistake here is to attempt to run it using your own local installation of python (e.g., by running python render.py or python3 render.py). Instead, we need to execute it through Blender’s python installation, by running /your/path/to/blender --background --python render.py where it should be noted that the path is to the blender binary, not the application. For example, on my MacBook, the path is /Applications/Blender.app/Contents/MacOS/Blender. Since we will often use this command, it can be useful to define a shorthand alias; for example, in my ~/.bash_profile I have added alias blender='/Applications/Blender.app/Contents/MacOS/Blender' function blender-python() { if [ \"$1\" == \"-q\" ] || [ \"$1\" == \"--quiet\" ] ; then blender --background --python \"$2\" 1\u003e /dev/null else blender --background --python \"$1\" fi } which allows me to use blender to refer to the whole path above, and blender-python to add the --background --python options. Then, we can just do blender-python render.py Command line aliases can be a little tricky, so if this does not work for you, do not fret. Just swap blender-python for /your/path/to/blender --background --python in all that follows. Alright! Hopefully our imports worked and render.py executed without issues. We can now start creating our Blender file programatically. Our first step will be to initialize a scene with a given resolution. We could do this by adding this after the imports: resolution_x = 100 resolution_y = 100 bt.blenderInit(resolution_x,resolution_y) In practice, it can be useful to have a parameter mult that we can use to easily alternate between the low resolutions we tend to use for prototyping and the high ones for final figure versions: mult ","date":"2022-05-29","objectID":"/blender_course_scripting.html:0:0","tags":null,"title":"Blender Course III: Rendering static images and animations programatically using Blender scripts","uri":"/blender_course_scripting.html"},{"categories":null,"content":"Camera Once we have imported the object, the next critical element we need to take an image of it is a camera. In a similar way to how we set up the mesh, we will import the camera with zero rotation and translation # add camera cam_location = (0,0,0) cam_rotation = (0,0,0) cam = bt.setCamera_from_UI(cam_location,cam_rotation) then open the generated test.blend: We can now move the camera until the optimal position is found and update our render.py accordingly: # boring imports import sys, os, bpy, bmesh import numpy as np this_file_path = os.path.dirname(__file__) sys.path.append(os.path.join(this_file_path,'BlenderToolbox')) import BlenderToolBox as bt # initialize shape mult = 1 # make this 1-5 for fast, 10-15 for final paper resolution_x = 100*mult resolution_y = 100*mult numSamples = 100*mult # no need to understand what this does yet bt.blenderInit(resolution_x,resolution_y,numSamples=numSamples) # read mesh path_to_mesh = this_file_path + '/dog.obj' mesh_location = (0,0,0) mesh_rotation = (90,0,0) mesh_scale = (1,1,1) mesh = bt.readMesh(path_to_mesh,mesh_location,mesh_rotation,mesh_scale) # add camera cam_location = (2.5,-5,1) cam_rotation = (75,0,25) cam = bt.setCamera_from_UI(cam_location,cam_rotation) # save to blend file save_path = this_file_path + '/test.blend' bpy.ops.wm.save_mainfile(filepath=save_path) Render with command line Alright! We have an object and a camera: that’s the minimal set we need to render a picture. We can do it with one last line of code: image_path = this_file_path + '/image.png' bt.renderImage(image_path, cam) such that our full render.py looks like this: # boring imports import sys, os, bpy, bmesh import numpy as np this_file_path = os.path.dirname(__file__) sys.path.append(os.path.join(this_file_path,'BlenderToolbox')) import BlenderToolBox as bt # initialize shape mult = 5 # make this 1-5 for fast, 10-15 for final paper resolution_x = 100*mult resolution_y = 100*mult numSamples = 100*mult # no need to understand what this does yet bt.blenderInit(resolution_x,resolution_y,numSamples=numSamples) # read mesh path_to_mesh = this_file_path + '/dog.obj' mesh_location = (0,0,0) mesh_rotation = (90,0,0) mesh_scale = (1,1,1) mesh = bt.readMesh(path_to_mesh,mesh_location,mesh_rotation,mesh_scale) # add camera cam_location = (2.5,-5,1) cam_rotation = (75,0,25) cam = bt.setCamera_from_UI(cam_location,cam_rotation) # render image_path = this_file_path + '/image.png' bt.renderImage(image_path, cam) # save to blend file save_path = this_file_path + '/test.blend' bpy.ops.wm.save_mainfile(filepath=save_path) If we now run blender-python render.py, we will get a new image in our directory dir/ └── BlenderToolbox/ └── render.py └── test.blend └── dog.obj └── image.png which, for now, looks like this (generated with mult=5): It is very dark! And the reason is obvious: we have not added any lights yet. Let’s do just that. Lights: ambient, sun, three point The Blender Toolbox gives us many different lighting options. For example, the simplest light one can add is a sun: light = bt.setLight_sun((45,45,45),1.0) # 45 is the angle, 1.0 is the brightness A sunlight generally results in very sharp shadows: Sharp shadows can be very aesthetically pleasing; however, they are generally not recommended for our research purposes, since they the shaded areas are so dark that they obscure the shape’s geometric detail. A way of getting around this is to add a soft ambient light, which adds brightness to every part of the scene to avoid extremely dark areas: light = bt.setLight_sun((45,45,45),1.0) bt.setLight_ambient(color=(0.2,0.2,0.2,1.0)) # 0.2 is the \"strength\" (from 0:black to 1:white) This is the rendered output we get: As expected, an ambient light avoids the extremely dark areas of the object, but it does so at the cost of over-lighting the areas that were exposed to the sun light, washing over some of the geometric detail. A better choice for a lighting setup is the classic photographic technique called three poin","date":"2022-05-29","objectID":"/blender_course_scripting.html:0:1","tags":null,"title":"Blender Course III: Rendering static images and animations programatically using Blender scripts","uri":"/blender_course_scripting.html"},{"categories":null,"content":"I keep forgetting how to do this well, and most of the tricks I find if I just google don’t work for me. So, future Silvia, here’s what you do: Run pip install arxiv-latex-cleaner Run arxiv_latex_cleaner --compress_pdf path/to/tex/folder Compress the new folder path/to/tex/folder-ArXiv and upload that to ArXiv ","date":"2022-03-30","objectID":"/arxiv_compressing.html:0:0","tags":null,"title":"Compressing a massive TeX folder for submitting to arxiv","uri":"/arxiv_compressing.html"},{"categories":null,"content":"A guide to running a weekly virtual colloquium","date":"2022-03-19","objectID":"/colloquium.html","tags":null,"title":"Running a weekly virtual colloquium","uri":"/colloquium.html"},{"categories":null,"content":" Written in collaboration with Hsueh-Ti Derek Liu In September 2020, together with Seungbae Bang and under the advisement of Professor Alec Jacobson, we founded the Toronto Geometry Colloquium, a student-run, weekly virtual webseries about geometry processing. Since then, we have successfully organized four seasons of our colloquium, which is still ongoing. In two years, we have hosted almost 80 speakers and accumulated over twenty thousand audience views. This document has two purposes: By the student-run nature of our colloquium, it is expected that organizers will graduate, go off on internships or step down for many other reasons. At the same time, new students will join the team with fresh energies and new ideas. We want this to serve as an internal guide for any future additions to our team, who will hopefully continue our colloquium in one way or another after the original organizers have (reluctantly!) moved on. Starting this colloquium was a lot of work. We have been approached by groups of students who want to organize similar initiative in other disciplines and institutions. By writing this guide, we hope to make the work of starting your own webseries slightly easier, so that we can all enjoy more diverse, quality talks in the future. We will organize this guide as a chronological checklist, grouping simultaneous tasks by topic. ","date":"2022-03-19","objectID":"/colloquium.html:0:0","tags":null,"title":"Running a weekly virtual colloquium","uri":"/colloquium.html"},{"categories":null,"content":"2+ months before series launch These items are a lot of work, but we speak from experience when we say that it is work that will get very quickly amortized as you start hosting the series. Important decisions and internal logistics Decide on a mission. This sounds abstract, but it will become important later on as you decide on speakers and judge success. Some interesting questions to ask yourselves and make sure you agree on before you start: What (and how large) is your target audience? , Who are your target speakers?, How broad are the topics you are willing to cover?. Most importantly, What does success look like? Would producing a very popular series that covers only the most popular of topics with the most well-known speakers satisfy you? How about one that is less accessible, but very important to its niche audience? Or one that loses on nuance in favour of being accessible to the newest of undergraduate students? Or one that introduces new speakers to your field?. As an example, you can find our colloquium’s mission at the top of our website. Decide on a format. Ideally, this will be something that makes your webseries special. In our case, we took inspiration from live comedy or music shows and decided to pair an “opener” (more junior, speaking usually about one recent work) speaker with a “headliner” (usually more senior, giving a keynote-style talk that includes many works). Decide on a rough timeline: when do you want your first session to be? How often do you want to host sessions? When will you have breaks between seasons? Gather a (large) list of potential speakers that adjust to your mission statement. Survey members of your lab or colleagues about people they would be interested in hearing from, write down the names of authors of papers you really like. Don’t be afraid of being selfish: is there someone you are whose work you are really excited about? Add them to the list. A hundred names is an ambitious but reasonable target. Create a spreadsheet that all organizers have access to, containing all past and future session dates (see below). Set very clear rules and conventions for adding names to this spreadsheet: for example, names in italics denote “people we are considering inviting”, names in roman font denote “potential speakers that we have invited but have not yet responded” and names in bold denote “speakers that have agreed to participate”. This will help make it very clear which dates are filled and which dates aren’t, and will avoid the situation where several speakers are offered the same date. Agree on a distribution of labour among the team members. Running this (especially if it’s weekly) is a lot of work, so it is very important to parallelize it efficiently. Everyone should be confident that they can fulfill their own role, and everyone should trust all others to fulfill it, keeping horizontal communication to a minimum. For example, you may appoint a poster person, an email person, a social media person, a tech person and a host. In our case, the host role rotates weekly, while some people may take on more than one of the other roles at a given time. We will color-code the items of this mega-checklist so that each person can quickly identify their own personal checklist. Items in black should be shared by all. Tech preparation Create a simple website for your series of talks. You can spend as long as you want on this, but the minimal requirement is that it should list all upcoming talks, your mission statement and should link to all your social media. We are not expert web programmers but if you want to start somewhere, our html website repo is public. We use github pages to host the website for free. Create a Google Account and its Youtube Channel. Use your google account to create an empty, public Google Calendar where you will add any confirmed talks. We have found this is a the simplest, most accessible way of keeping a schedule. Create (or make sure you have access to) a Pro Zoom Account,","date":"2022-03-19","objectID":"/colloquium.html:1:0","tags":null,"title":"Running a weekly virtual colloquium","uri":"/colloquium.html"},{"categories":null,"content":"Session checklist Once you are done with all the items above, you are ready to start your webseries. It’s now time to prepare and run each individual session. Of course, the checklists for different sessions intersect: as you are inviting one speaker, you may be preparing the previous session’s poster and you are hosting the session before that. Something that has worked for us is setting a weekly time, for example, Mondays at 5 pm, where one goes through their role’s checklist for every upcoming talk as well as the shared spreadsheet and makes sure they are not behind schedule. This will also help limit your time commitment. 2 months before session Choose and contact an artist to produce the session’s poster. In the first email, you can inform them of the deliverables (in our case, two portrait images and one main illustration), deadline (ideally, at least 14 days before the session date) and budget (the 500 dollar range is a reasonable one). You do not need to provide many details yet, so you can do this before you have confirmed the speakers. Here’s an example of what that email can look like. If they refuse or you don’t hear back, ask a different artist until one accepts. Choose the speakers for the session. Anyone in the team can suggest names from the list, but care should be taken that the decision to invite them is unanimous. Send invitation letters to your chosen speakers. If they refuse or you don’t hear back from them, go back to the previous step and repeat until you have confirmed the speaker’s participation. Remember to keep the spreadsheet updated. Note: This action item can be very labor intensive, especially in the month before the series launch, so other team members may help with this step as well. A reasonable goal is to always have two pending invitations in the months before the series launch, to not get behind on filling up speaking slots. 1 month before session Add confirmed speakers to Google calendar and website. Send first reminder email to speakers, asking for talk title. You can send this email right after the speaker confirms. Send an email to the confirmed artist with all the poster details: speakers, topics, prompt, format, sketch deadline (usually a week before the final art deadline). Here’s an example of what this email can look like. 2 weeks before session Converge with artist on final poster. 1 week before session Create Youtube link for the session, using poster art. Create Zoom link for the session. Importantly, make sure you are enabling the Zoom waiting room and the room has a password that you only share with your team and the speakers. Add Youtube link to Google calendar and website. Add poster to the website. Start promoting the talk with posts on all social media, using poster art. Email second reminder to speakers. Day before session Write a detailed script. Don’t rush this step. Learn about the speakers, read their work, and craft proper, personalized, generous introductions for each speaker. They prepared a whole talk to present to you, they deserve a proper introduction. Here’s an example. Day of session 30 minutes before session start (T-30m) Share a reminder about the talk on all (internal and external) channels, including social media, with the live stream link. (T-15m) Open the Zoom room for the session. Make sure you are in “Speaker” view, not in “Gallery” view in Zoom. (T-15m) Open Youtube Studio. Enter the live stream control room. (T-15m) Welcome speakers to the room. (T-13m) Click on “Start livestream on custom live streaming service” in the Zoom room. It will take you to a website with some textboxes to fill. Use the information in the Youtube Studio livestream control room to fill these items out, and click on “Start Streaming”. (T-10m) Do a quick tech check with all speakers: check that they can properly share screen, that their videos/audio are shared properly. (T-5m) Explain process to speakers.Here’s my script for this step (T-2m) Share screen with session poster ","date":"2022-03-19","objectID":"/colloquium.html:2:0","tags":null,"title":"Running a weekly virtual colloquium","uri":"/colloquium.html"},{"categories":null,"content":"For the most part, you can open and render your Blender 2.9 files using the new and improved Blender 3.0. You may want to do this because Blender 3.0’s rendering is extremely improved from the previous versions or because you started a project on 2.9/2.8 and now want to continue it in 3.0. There is only one compatibility issue I have encountered, but it can completely destroy your render. Say your Blender 2.8/2.9 file used compositing nodes, like my Blender 2.9 template paper figure file. The compositing view in Blender 2.9 may look like this: As you can see, we are passing “Noisy Image” from our render to the “Denoiser” node. However, if we open this same file in Blender 3.0, we see the following: The “Noisy Image” output has disappeared! And therefore nothing is going into our “Denoise” node. This is (I think) because Blender 3.0 no longer does denoising as post-processing in the compositing step; instead, you can turn on “Denoise” in the Render Output panel. If we choose to render the image, we will get empty RGB channels, because no RGB channels are entering the denoiser: Fixing this is simple: just circunvent the denoising node and connect the “Image” output from the Render node with the “Image” input of the next node in the chain; in my case, the “Bright/Contrast” one: And we can render and composit to get the expected result: ","date":"2022-03-03","objectID":"/blender_compositing_compatibility.html:0:0","tags":null,"title":"PSA: Update your compositing nodes for 3.0","uri":"/blender_compositing_compatibility.html"},{"categories":null,"content":"Every time I try to code a project in C++ I run into the same bugs, and I keep forgetting how to solve them. So, I decided to write this list here for my own reference. ","date":"2022-01-27","objectID":"/cpp_bugs.html:0:0","tags":null,"title":"Bugs I often write in C++","uri":"/cpp_bugs.html"},{"categories":null,"content":"Eigen initialization bug Symptoms: The code compiles and runs properly, but the output seems random and changes from one run to the next, despite the code being theoretically deterministic. Diagnosis: This happens because you am declaring a variable and calling it without initializing it. For example, Eigen::Matrix\u003cint,3,5\u003e A; will not create a matrix A of zeros, instead it will fill with entries with garbage from the computer’s memory. Treatment: Go variable by variable and ensure that it is being properly initialized after being declared. For example, instead of Eigen::Matrix\u003cint,3,5\u003e A;, write Eigen::Matrix\u003cint,3,5\u003e A; A.setZero(); ","date":"2022-01-27","objectID":"/cpp_bugs.html:0:1","tags":null,"title":"Bugs I often write in C++","uri":"/cpp_bugs.html"},{"categories":null,"content":"Linker error Symptoms: The code seems to compile well but breaks just at the end of the compilation process, returning an error like ld: symbol(s) not found for architecture x86_64. Diagnosis: This happens because you are not compiling one of the source files you’re using. For example, you wrote main.cpp which itself includes another function you wrote in func.cpp,func.h, but you are only compiling main and not func. Treatment: If you are using CMake (and func is in a path that CMake checks for source code, e.g., include/ or /src if you are using CMake best practices), remove all CMake cache and build the project again, rm -rf build mkdir build cd build cmake ../ If you are not using CMake (even though you should) and instead compiling by calling your compiler directly from the terminal like gcc main.cpp -o main, then add func.cpp to the source files being compiled by calling instead gcc main.cpp func.cpp -o main. ","date":"2022-01-27","objectID":"/cpp_bugs.html:0:2","tags":null,"title":"Bugs I often write in C++","uri":"/cpp_bugs.html"},{"categories":null,"content":"Multiple inclusions Symptoms: Compiling fails with errors like error: redefinition of ... or ... included multiple times. Diagnosis: This happens because, when compiling, the compiler is reaching the same function or variable definition many times. For example, say we have a function main.cpp: #include \"func.h\" #include \"func2.h\" int main(int argc, char *argv[]) { func(0); func2(0); } which calls functions func.cpp #include \"func.h\" void func(int a){ std::cout \u003c\u003c a \u003c\u003c std::endl; } with header file func.h: void func(int a) and func2.cpp #include \"func2.h\" void func2(int a){ func(a+1); } with header file func2.h: #include \"func.h\" void func2(int a) When the compiler sees an include statement, it will literally just copy that file at that position in the code; and, of course, this works recursively. Therefore, since main is including func.h and func2.h, which in turn also includes func.h, when the compiler starts reading main.cpp and sees #include \"func.h\" #include \"func2.h\" it will interpret it as void func(int a) #include \"func2.h\" and then void func(int a) #include \"func.h\" void func2(int a) which recursively turns into void func(int a) void func(int a) void func2(int a) Thus, even without knowing it, we were defining the same function twice to the compiler’s eyes, and that makes it crash. Treatment: The best way to be protected against this is always using include guards, a smart trick to ensure that the compiler will only enter the main text of each header file once. Basically, envelop every header file you ever write in an if statement like this: #ifndef UNIQUE_NAME #define UNIQUE_NAME // header code here #endif Make sure that UNIQUE_NAME is unique for each header file and it never shares a name with any file or variable or functions ever read by the compiler. For example, you can make them all caps and make sure you never write all caps variable or function names. So, in our example, we would make func.h #ifndef FUNC #define FUNC void func(int a) #endif and func2.h #ifndef FUNC2 #define FUNC2 #include \"func.h\" void func2(int a) #endif By doing this, we avoid the compiler entering the same code twice and we avoid the error ","date":"2022-01-27","objectID":"/cpp_bugs.html:0:3","tags":null,"title":"Bugs I often write in C++","uri":"/cpp_bugs.html"},{"categories":null,"content":"In my experience, PhD Committee Meetings are an obscure, secretive part of the PhD requirements. One reason for this is that they vary greatly from student to student and discipline to discipline. Still, it is undeniably yet another way in which people without family/friends in academia are gatekept away from it. When it is your time to prepare a PhD Qualifying Exam or PhD Yearly Checkpoint, it is likely you have never even seen what one looks like before, since they are private events, and have to rely on asking around for examples of successful ones. I know this because it is what I did when I was starting out and because, in the past two or three months, I have been asked for my own old documents many times. Therefore, I am posting them here so they are accessible to everyone, regardless of whether they email me or not. As it is now tradition with these types of posts, I must precede everything with a big DISCLAIMER. While these documents worked for me, I am not claiming they are perfect or a model to follow. I post them here so you can look at them and judge for yourself which parts are good or bad or which parts you should take inspiration from. Furthermore, obviously my documents are very related to my own line of research, so copying what I wrote word for word will be of little use to you. And finally, I have found PhD requirements vary heavily from institution to institution. I used the following documents to survive to my third PhD year at the University of Toronto Computer Science Department. If you are reading this from another institution, I strongly recommend you look for examples there. Okay, that being said, here you go (I’ll try to update this list as I progress): ","date":"2021-10-07","objectID":"/phd_committee.html:0:0","tags":null,"title":"Preparing PhD Committee Meetings","uri":"/phd_committee.html"},{"categories":null,"content":"Qualifying Exam Here’s the pdf document I sent to my committee one month before my qualifying exam in 2020 Here are the slides (keynote (recommended) , ppt ) I used for my qualifying exam 15 minute presentation in 2020. Make sure to enable presenter notes to also see my script. ","date":"2021-10-07","objectID":"/phd_committee.html:0:1","tags":null,"title":"Preparing PhD Committee Meetings","uri":"/phd_committee.html"},{"categories":null,"content":"Yearly PhD Checkpoint Here are the slides (keynote (recommended) , ppt ) I used for my first yearly PhD checkpoint in 2021 (Please email me if any of the links above are broken) ","date":"2021-10-07","objectID":"/phd_committee.html:0:2","tags":null,"title":"Preparing PhD Committee Meetings","uri":"/phd_committee.html"},{"categories":null,"content":"Today, September 30th 2021, marks the first National Day for Truth and Reconciliation. A few months ago, I was awarded an NSERC Vanier Graduate Scholarship. I felt incredibly honoured that, less than two years after arriving in this country, the Canadian government was making a choice to bet on my research and spend hard-earned Canadian taxpayer’s money on me. It came at a strange time, though, as we were getting daily reminders of the historical and present systemic neglect, erasure and discrimination faced by Indigenous people in Canada. It was hard not to feel like the same government was choosing to invest money in me, a white privileged European with no connection to this land, rather than on alleviating these injustices. This didn’t sit right with me, so after giving it some thought I decided to donate an amount equivalent to a portion of my scholarship to the following charities, and to make it public to encourage all of you who receive government funding to consider doing it as well: The Indian Residential School Survivors Society provides essential services to Residential School Survivors, their families, and those dealing with intergenerational trauma. Donate here. Residential “schools” were “schools” in name only. Systemic barriers make it so Indigenous people in Canada have been and are still denied a quality education. Indspire is a national charity that invests in the education of First Nations, Inuit and Métis people. Donate here. 13.5% of First Nation communities in Canada and 40% of First Nation communities in Ontario do not have access to safe drinking tap water. Water First’s mission is to help address local water challenges in Indigenous communities through education, training and meaningful collaboration. Donate here. One quarter of all Indigenous people and one third of all Indigenous children in Canadian urban areas live below the poverty line. Our neighbours in the Native Canadian Center of Toronto empower the Indigenous community in Toronto by providing programs that support their spiritual, emotional, physical and mental well-being. Donate here. ","date":"2021-09-30","objectID":"/truth_and_reconciliation.html:0:0","tags":null,"title":"National Day for Truth and Reconciliation","uri":"/truth_and_reconciliation.html"},{"categories":null,"content":"In 2021, I won a Vanier Canada Graduate Scholarship. Out of 190 total eligible NSERC applicants, I was ranked 43, with scores of 6.50 in Academic Excellence, 6.25 in Research Potential and 7.00 in Leadership (I don’t really know a lot about what these numbers mean). NSERC gave out of 55 scholarships, so I got one. In the last five days alone, I have gotten four emails asking for advice about applying, so out of desire to (1) avoid redundancy and (2) not help only those who dare or are encouraged enough to email me, I am posting my answer here. Of course, the standard disclaimer applies: this is just what I did to apply, and from the numbers above you can probably tell there’s people who did much better than me, so take everything I say with a grain of salt and draw your own conclusions. Note: If you are a member of an underrepresented community in your discipline and want to chat about your application further than what’s described in this post, please email me, I am more than happy to talk. Apart from trivial-yet-boring items like filling out the Canadian Common CV and other forms, as well as your post-secondary transcripts, the Vanier Scholarship application consists of the following: A research statement A “Research contributions” document Two research reference letters A leadership statement Two leadership reference letters Let’s go one by one: ","date":"2021-08-09","objectID":"/vanier_scholarship.html:0:0","tags":null,"title":"My application for the Vanier Canada Graduate Scholarship","uri":"/vanier_scholarship.html"},{"categories":null,"content":"Research Statement For this item, I submitted my standard research statement, which I used with minor changes to apply for all kinds of awards and scholarships during the Summer/Fall 2020 application season. If you have successfully applied for research awards before, you know what this is and how to do it (probably better than I do). I divide it in three parts: an (accessible) introduction which sets up a general, exciting vision for my research, a summary of past works that evidences my ability to succeed, and a review of specific project ideas for the future, both concrete and more general. You can find my statement (with some parts redacted because they are ongoing projects) and references here. Please use it for your own reference and don’t share it or post it anywhere else. Also, don’t use it as an example, it was described by people who know more about this than me as “an OK statement” and “it won’t hurt you, but it probably won’t help you either”, so you can probably do much better than this. ","date":"2021-08-09","objectID":"/vanier_scholarship.html:1:0","tags":null,"title":"My application for the Vanier Canada Graduate Scholarship","uri":"/vanier_scholarship.html"},{"categories":null,"content":"Research Contributions This was a kind of unorthodox document to write, but still straightforward: I listed the research projects I had worked in prior to my application and my role in them. If it helps, you can find mine here. For each project, I also tried to summarize their impact, although this was probably redundant given they are all peer-reviewed, published works. ","date":"2021-08-09","objectID":"/vanier_scholarship.html:2:0","tags":null,"title":"My application for the Vanier Canada Graduate Scholarship","uri":"/vanier_scholarship.html"},{"categories":null,"content":"Research References The usual advice for research references is to pick people that (1) have seen you do research and (2) are respected in the field, in that order of priority. I strongly recommend one of these is your PhD advisor; otherwise, your advisor not writing a letter for you can be seen as a major red flag. In my case, I asked both my PhD advisor and an industry researcher who mentored me on a research internship that ended in a published paper. They were both generous enough to accept, and since they submit their letters privately through the ResearchNet server, I don’t have much to add. A common question is What do I do if I have only ever done research with one person; for example, my PhD advisor? Who can be my second reference? This will heavily depend on your discipline and specific situation but, generally, I would say it is better to pick someone in your field who you haven’t worked with directly but who knows you and your work (say, another professor in your advisor’s department or lab) rather than a senior professor who knows nothing about your research. ","date":"2021-08-09","objectID":"/vanier_scholarship.html:3:0","tags":null,"title":"My application for the Vanier Canada Graduate Scholarship","uri":"/vanier_scholarship.html"},{"categories":null,"content":"Leadership Statement This was one of the hardest parts of my application, and I had to make it up as I went along since I had no example of a successful leadership statement. The Vanier application site specifically suggests that you mention sports and musical achievements, of which I have absolutely zero, so I had to think outside the box. I decided to focus on my social and political activism as well as my role in LGBT+ struggle, as you can see here. Again, this document contains personal information so I would appreciate it if you just kept it to yourself and not share it around. Update: The wiriting on the Vanier application website’s section on the Leadership statement has been greatly expanded since I applied. I recommend you read the current writing and try to see if any of your circumstances fall into the described categories. ","date":"2021-08-09","objectID":"/vanier_scholarship.html:4:0","tags":null,"title":"My application for the Vanier Canada Graduate Scholarship","uri":"/vanier_scholarship.html"},{"categories":null,"content":"Leadership references I really, really struggled with this item. My personal opinion is that this item is yet another institutional barrier that discriminates against students that come from countries outside North America whose languages are different from English and French and do not have the tradition of writing reference letters. It honestly feels incredible that they keep this as an application item. But oh well, what are we going to do, we don’t make the rules. I arrived in the English/French speaking world in late 2019, so despite having done activism and volunteering in my life, I don’t have anyone in a leadership role in my life who can write a good letter in any of these languages attesting to my life and research trajectory. I also haven’t done any music training or sports either. So I had no idea who to ask for a leadership letter, let alone two. To make it even more awkward, you must submit the letters, not the recommenders themselves, so it will be hard to convince people from the academic world to write one for you since they are used to submitting confidential letters. I started by asking an amazing professor who visited our lab for a sabbatical year, whom I had never done research with but with whom I had built a nice professional relationship during her year here. She was nice enough to write a really generous letter about me, emphasizing my work to keep morale up within our lab and to offer to help people whenever they need help with anything, as well as to include people in our lab’s social events. I am obviously not going to share her letter here publicly. I spent weeks without a second leadership letter. I asked a labmate of mine, who I thought maybe could attest to the same items the previous recommender had, but he (probably correctly) politely recommended I ask someone else. Then, I rememberd a friend of mine from my undergrad was now studying in the UK, and I asked him to write me a letter as a personal favour. He emphasized my activism during our college years as well as my struggles as a trans person enduring institutional discrimination during those years. Again, I am not going to share his letter publicly. I really thought this item would be the one I would lose the scholarship over. My only senior, leadership-position recommender was academic, which went slightly against the stated spirit of the letters, and she had only known me for under a year. My other letter was from a first-year Master’s student who had been my peer and also from an academic background, and all he did was reaffirm what I had already brought up in my own leadership statement. However, I got my highest score in the Leadership item, so I must have done something right inadvertently. ","date":"2021-08-09","objectID":"/vanier_scholarship.html:5:0","tags":null,"title":"My application for the Vanier Canada Graduate Scholarship","uri":"/vanier_scholarship.html"},{"categories":null,"content":"Closing thoughts Anyway, I hope this was useful! If you find any mistake or think I should add anything to this guide here, or if you’re a member of an underrepresented community in your discipline and want to chat about your application, email me. ","date":"2021-08-09","objectID":"/vanier_scholarship.html:6:0","tags":null,"title":"My application for the Vanier Canada Graduate Scholarship","uri":"/vanier_scholarship.html"},{"categories":null,"content":"In my years in academia as the only trans person in the roomTM, I have often been asked for or volunteered my advice on how to ask for people’s name and gender on official forms like conference surveys, program registrations or award applications. I tend to always reply with a version of the same answer, so in the interest of my own reference and that of rooms without any trans people in them, I post it publicly here. Important disclaimer: What follows is exclusively my own, personal, subjective opinion, as one trans person with experience filling out and creating these forms. I speak only for myself, and not for any group of people. Following this advice does not absolve you or shield you from criticism from other people with experiences different from my own. If you are looking for the answer to How should I ask about people’s name and gender in this form?, there are many resources written by much better informed, more knowledgeable people than me whose job it is to answer this question. You probably want to click on one of the following links instead of continuing reading this post: UBC’s Equity and Inclusion Office’s “Inclusive Forms”. Vanderbilt LGBTQI office’s “Asking about sex, gender, or sexual orientation on a form, survey or project”. Keshet’s “A guide to Creating LGBT-Inclusive Forms”. Despite the existence of these resources (they are all on the first google search page for “trans inclusive gender form” as I type this), academic forms in my field, even when written with the best of intentions, tend to not incorporate a lot of the common advice in the links above. Perhaps, I imagine, this is because it can be hard to know which links to trust and it is easier to follow advice if it comes from someone you know and (hopefully) trust. So, if you are looking for the answer to hey Silvia, how would you ask about name and gender in this form?, then you are in the right place. What follows is my usual answer. ","date":"2021-07-04","objectID":"/gender_question.html:0:0","tags":null,"title":"Silvia, how would you ask about name and gender in this form?","uri":"/gender_question.html"},{"categories":null,"content":"Do you really, really need to ask for people’s gender? Gender is a deeply personal part of how a person perceives themselves. For many, being asked about their gender is just as invasive a question as being asked for your religious affiliation or sexual orientation. So, before including a question about gender in a form, ask yourself: Why do I need this information? The following are (some) not valid answers to this question: You never know! I am curious. We are inheriting a form from years ago that asked about gender. We use an IT system that asks about gender by default. It’s just standard demographic data! I want to know what pronouns to use when addressing someone (in this case, you want to ask about pronouns, not about gender). Some valid answers (may) include: I want to collect aggregate demographic data to analyze the gender parity of the event attendees. I know gender minorities face additional challenges in academia so I want to weigh a person’s gender when evaluating their application. Assuming you have a valid answer to the question above, here’s some advice: Drop “preferred”, “self-identified”, “womxn” and similar words; instead, be explicit My understanding is these words are usually added with the best of intentions to ensure that a trans person filling out the form does not feel the need to deadname or misgender themselves. This is an admirable goal. However, my reaction to these terms is that it feels patronizing (talking about someone’s preferred name or someone being woman-identifying makes it sound in contraposition to someone’s real name or real women) and, more importantly, it feels to me like using dogwhistle words that the author of the form uses as a signal only to trans people that the form is trans-inclusive but in a way that impacts the experience of cisgender people the least. Ask yourself: why am I making such an effort so that cisgender people do not realize that this is a trans-inclusive form? Instead of using these words, be explicit and send a message to all people. For example, instead of asking for a person’s preferred name and preferred pronouns, your form can look like this: Name: We are a trans-inclusive organization. Pick whichever name you would like us to refer to you by Pronouns: We are a trans-inclusive organization. Pick whichever pronouns you would like us to use to refer to you in the third person. Explain what the answer will be used for Many trans people will answer gender/name/pronouns questions differently depending on what the answers will be used for. If the name will be used for tax reasons, a trans person may use a different name than if the name will be used to address that person in emails, and a different name than if it will be shared publicly or used for sending regular mail to the person’s address. Instead of assuming which name people use for each purpose, state the purpose clearly and let the person make the informed choice. For example: Name: We will use this name to refer to you in our emails to you. Gender: For aggregate, statistical purposes only. or Name: We will use this name in all our payroll documentation and tax forms. It will not be shared with anybody else. Gender: We are a trans-inclusive organization. We are proud to be an affirmative action employer and do not discriminate based on race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability status, or any other applicable characteristics protected by U.S. law. or Name: We will share this name, next to your photo, in our website and advertising materials. As stated above, if you do not know the purposes for which you will use the gender information, that is probably a sign that you do not need to be asking about it. Make it (or, at a minimum, add a) write-in option Ideally, gender should be a write-in field. Only if your form is going to be used by so many people that manually parsing the answers will be impossible, you may use a multiple-choice question, but this o","date":"2021-07-04","objectID":"/gender_question.html:0:1","tags":null,"title":"Silvia, how would you ask about name and gender in this form?","uri":"/gender_question.html"},{"categories":null,"content":"(Good) Examples From the WiGRAPH mailing list sign-up sheet. From SGI ","date":"2021-07-04","objectID":"/gender_question.html:1:0","tags":null,"title":"Silvia, how would you ask about name and gender in this form?","uri":"/gender_question.html"},{"categories":null,"content":"Every few months, because of a deadline coming up, I find myself forgetting and having to look up these steps in old Slack threads and LaTeX comments. Also, it took me a long time to learn these steps because of the lack of a guide like this, so I write this in hopes it may help young students starting out. I will assume that you have a set of meshes in .obj format, with ordered names like iteration-001.obj, iteration-002.obj, … iteration-099.obj, iteration-100.obj. Open Blender (you can use my template file). Install the OBJ Sequence Blender add-on. In Blender, press SHIFT+a and choose Mesh-\u003eMesh Sequence. Then, an empty object called “sequence” will appear in the scene. Select this object and go to Object Properties -\u003e Mesh Sequence. Choose the root folder where your .obj files are, being careful to uncheck relative pathing (this is a bug in the Mesh Sequence Add-on). Then, in “file name”, write a string which matches the beginning of the names of all meshes, like iteration. Finally, click “Load Mesh Sequence”. This can take a few minutes if your meshes are many or very large. In Output Properties-\u003eDimensions, choose the dimensions of your animation in pixels (for example, 1920x1080px). In some versions of Blender, the “End” frame is set to 250 by default. This will make your “Baking” step much more expensive than necessary if your animation contains way less meshes, and you may miss the end of your animation if there are more than 250 meshes in your sequence. Make the “End” value the total number of meshes in your sequence (careful with 1-indexing and 0-indexing). Now, finalize all the details of your scene. It is especially important that at this step, you pick the materials and shading information for your mesh sequence, since you will not be able to change it afterwards. At this point, I usually save a copy of my .blend file called pre-bake.blend so that I can go back to this step if I want to iterate on my result. In Object Properties-\u003eMesh Sequence, choose Smooth or Flat shading and click “Bake Mesh Sequence”. Now, if you go to the “Animation” tab, you can press Play or drag the blue time bar to see the progression of your animation. In Output Properties-\u003eOutput, make sure your output directory is set to a known relative path like // or //pngs/. This is important, because some Blender make /tmp/ by default and you may completely lose your renderings if you don’t change this. Select “File Extensions”, unselect “Cache Result”, choose “File Format: PNG”, “RGBA”, “Color Depth: 8”, “Compression: 15%”, select “Image Sequence: Overwrite” and unselect “Image Sequence: Placeholders”. Save and exit Blender. Now, in the command line and in the same directory as your .blend file. Run blender -b filename.blend -a. This will take a while. The rendering step will create a sequence of .png like 001.png, 002.png, …, 099.png, 100.png. These will be transparent, which doesn’t look great for an animation, so we can preprocess these by running mogrify -flatten *.png (this assumes you’ve installed ImageMagick, which in MacOS you can do with brew install imagemagick). Put the images together into a video by running ffmpeg -r framerate -f image2 -s 1920x1080 -i %04d.png -vcodec libx264 -crf 15 -pix_fmt yuv420p video.mp4, substituting framerate with how many of the pngs you want per second (this assumes you’ve installed ffempg, which in MacOS you can do with brew install ffmpeg). (Optional) If you want to reduce the size of your final .mp4 file, you can do so by running HandBrakeCLI -i video.mp4 -o 'video-compressed.mp4' -O --preset 'Normal' (this assumes you have installed Handbrake, which on a Mac is as easy as brew install handbrake) ","date":"2021-01-24","objectID":"/blender_videos.html:0:0","tags":null,"title":"Blender Course II: Rendering an animation with Blender","uri":"/blender_videos.html"},{"categories":null,"content":"There are many skills not necessarily related to geometry or math that are required to make a polished SIGGRAPH submission. Every submission season, I end up going through a combination of my memory from the previous season, old Slack threads that I can only find with very specific keywords and trusting that google remembers the last time I searched for these things. No more! I will list the resources here so that I can come back to this site when the deadline approaches and, who knows, maybe you will find it helpful too! A simple template for Blender renderings of static meshes. A guide for Blender renderings of static meshes for paper figures. How to make an animation of a mesh sequence with Blender. How to compress a massive tex folder so that it can be uploaded to arxiv. How to compress a PDF to ~20MB using Adobe Acrobat Pro (by Alec Jacobson). ","date":"2021-01-24","objectID":"/siggraph_submission_resources.html:0:0","tags":null,"title":"SIGGRAPH submission resource list","uri":"/siggraph_submission_resources.html"},{"categories":null,"content":"There are a lot of great Blender tutorials online (e.g., the classic donut tutorial by Blender Guru), and they are usually aimed at artists or animators who want to generate full scenes from scratch for short films. Therefore they go into depth on how to model a shape, how to pick the best lighting, how to design a material, create textures, etc. These are really interesting topics, but they can be overwhelming if you are an academic and all you want is to render your object beautifully for a SIGGRAPH paper figure. For this use case, there is way less documentation online (my labmate Derek’s Blender scripting toolbox is a great exception), and in my experience this can lead to a lot of frustration especially when nearing deadlines, when one does not have the time or energy to learn a whole new aspect of the software just for a minor change in a paper figure. Mitigating that frustration is the goal of this guide. Also, one only needs to look through SIGGRAPH publications to see that all labs seem to have their own really polished “paper-quality rendering” pipeline, but unfortunately in my experience these mostly stay at the “tricks of the trade” level and aren’t shared very widely (not out of malice, there just aren’t many incentives for it). Another goal of this guide is to share my pipeline with people from other labs so that they (you) can hopefully learn something but also teach me something I am currently doing wrong or less efficiently (please email me!). Anyway, here we go. Let’s pretend you wrote a fancy new method in C++ or Matlab or Python that outputs a mesh called output.obj, and you want to render it to put it in a paper figure (if you want to make an animation for your paper video, please see my other guide). Download my Blender template file. Open Blender (you can download it from here). You’ll see something like this Before you do anything, go to Edit-\u003ePreferences, and on the Keymap section, pick Spacebar Action: Search. This will give you a very useful way of navigating the UI, instead of looking for each button you can just press spacebar and search for whatever is you’re looking for. This is something Oded Stein taught me when I started using Blender and it will completely change how you use the software for the better. Click on the cube on the middle of scene and then on the letter X to delete it, we won’t be using it. Go to File-\u003eImport-\u003e.obj and select your output.obj. It should appear in the screen: Pan and move your view in the viewport until you have a good view of the object (the controls for this differ, but on my MacBook I use the trackpad with two fingers to pan, CMD + two fingers to zoom and SHIFT + two fingers to move the viewpoint). Then, use the spacebar and type “Align Camera to view”. Press ENTER and you should see the frame of a camera appear. At this point, we can still move our view around and all we need to do is click on the camera icon on the top right of our scene to go back to this camera view: Let’s add a ground plane. To do this, we press Spacebar again and type “Plane”, choosing the mesh plane option. Let’s scale the plane so that it covers all the ground seen in the image. To do this we go to the object properties (clicking on the orange/yellow square icon on the bottom-right toolbar), and input values for the X and Y scale; for example, 20 for each A good practice to have after we’ve done a transformation like a translation, rotation and scaling and we are happy with it, is to “apply it”, i.e., lock it and make it permanent, turning a 1-by-1 scaled up plane into a 20-by-20 unscaled one. The difference is nuanced but it will be noticeable if you later use textures or physics. To do this we just use the spacebar and type “Apply all transformations” A note: Blender loves crashing on you and deleting your progress. Save your .blend file and do it often. Let’s see how our figure is looking. Right now we are looking at our shape in the default viewmode, in which we can see the geometrie","date":"2020-11-11","objectID":"/blender_figure.html:0:0","tags":null,"title":"Blender Course I: Rendering a paper figure with Blender","uri":"/blender_figure.html"},{"categories":null,"content":"Rendering in a different computer If you choose to send your .blend file to another computer (for example, a lab server) to render, then it is important you also follow two extra steps. First, make sure to select “File-\u003eExternal data-\u003eAutomatically pack data into .blend” (otherwise your other computer won’t know where to look for the textures and objects in the scene). Also go to “Output Properties” and under “Output” make it a relative directory like // instead of the default /tmp/, or you risk losing your rendered images forever. ","date":"2020-11-11","objectID":"/blender_figure.html:1:0","tags":null,"title":"Blender Course I: Rendering a paper figure with Blender","uri":"/blender_figure.html"},{"categories":null,"content":"“There’s too much shadow” Sometimes, your rendered image will have long shadows that don’t allow you to use them well as transparent images in papers; or they have ambient lighting which leads to an almost undetectable shadow everywhere in the image, that becomes apparent only when you put it on a white background. You can solve this (as Oded Stein showed me) by re-mapping the alpha values in the Blender Compositor (see the “Compositor” tab in the top of your blender UI). Here’s an example of the nodes in my template file’s compositor. The top part does the shadow removal (play with the thresholds to get more/less shadow), while the bottom does standard image editing to avoid having to do it in another software. ","date":"2020-11-11","objectID":"/blender_figure.html:2:0","tags":null,"title":"Blender Course I: Rendering a paper figure with Blender","uri":"/blender_figure.html"},{"categories":null,"content":"“The render preview takes so long!” If, like me, you don’t own a supercomputer with powerful graphics cards, it may be that refreshing a render preview can take a long time, especially the more textures and files you have in your scene. It can ruin the feeling of interactivity in the software: what I like most about rendering paper figures using the Blender UI is that you can change something in your scene and see how that affects the image, and iterate like that. One way of getting this immediate feedback without spending thousands of dollars in graphics cards is to use a really nice feature called “Render Region”. Basically, this relies on the fact that when you’re iterating some aspect of your image, it is rare that you’re really looking everywhere in the figure to evaluate your changes. For example, if I am playing with the material of the main object, I could just look at one part of it to iterate instead of asking the render to simulate all the shadows and other objects in the scene. See what I mean by choosing the “Render Region” option, which I do by pressing Spacebar and searching for it: Then, I drag my mouse to select a really tiny region of my render I can them zoom in (CMD + Mouse Wheel in my Mac) and focus on the region I’m rendering: Since now the preview is only rendering this tiny part of the figure, it will update much much faster when you change aspects in your scene; for example, the width of the wireframe: Important: Make sure to remove your render region before you run the final render of your scene for your paper. I do this by Spacebar searching “Clear Render Region”. I have forgotten this step more times than I’d like to admit :) Contribute! This blog post is a work in progress which I hope can be useful, especially to new students starting out in our field and writing their first publication. Feel free to contribute to this post by emailing me suggestions and I’ll be glad to properly credit you for any addition/correction. ","date":"2020-11-11","objectID":"/blender_figure.html:3:0","tags":null,"title":"Blender Course I: Rendering a paper figure with Blender","uri":"/blender_figure.html"},{"categories":null,"content":" May 2021 Update: Here’s a thread from Prof. Pamela E. Harris crowdsourcing suggestions of questions to ask from the specific perspective of students belonging to underrepresented minorities. ","date":"2020-08-03","objectID":"/grad_questions.html:0:0","tags":null,"title":"Questions to ask as a prospective graduate student","uri":"/grad_questions.html"},{"categories":null,"content":"Money Minimum take-home monthly pay: What is the minimum amount I will make a month, once tuition and fees and immediate expenses are removed? Will I get this pay every month of the year? What exactly are my teaching/research obligations? For how many years am I guaranteed this funding? What happens if I do a visit/internship in a different institution? Maximum take-home pay: What bonuses could I get on this pay and how likely is it that I will get them as an international student? ","date":"2020-08-03","objectID":"/grad_questions.html:1:0","tags":null,"title":"Questions to ask as a prospective graduate student","uri":"/grad_questions.html"},{"categories":null,"content":"Immigration What exactly will my immigration status be while on the PhD program? Can I work, move, travel freely? I wish to move to the city with my spouse. Is it guaranteed that he will be granted a residence permit or an open work visa to come live with me? ","date":"2020-08-03","objectID":"/grad_questions.html:2:0","tags":null,"title":"Questions to ask as a prospective graduate student","uri":"/grad_questions.html"},{"categories":null,"content":"Specifically for prospective advisor Are you planning to relocate anywhere in the next five years? What happens if you relocate? Can I move with you? Or change advisor? How many graduate students do you currently have, or plan to have by Fall 2019? How many postdocs? Do you usually have weekly or biweekly meetings with your graduate students? Are graduate students effectively supervised by you, or mostly by postdocs and more experienced students? What are daily lab hours like? Is the lab open on weekends and holidays? Am I expected to work weekends and holidays (exceptionally or not)? What exactly is my attendance requirement? This is to say, can I occasionally take on one-week trips home to Europe outside of conventional university breaks? What is your personal policy on paper authorship? In which companies do you have particular acquaintances that would allow me to do short/long internships? Am I expected to do these internships? What are the requirements (both minimum and expected) for a PhD in your laboratory? Broadly, how do you envision the 4/5 years of my prospective PhD to be? When/Do you expect me to take courses? When/Do you expect me to do internships or visits to other campuses? When should I begin working towards my thesis? What is the approximate gender ratio of your laboratory and department? Specifically, how does this ratio change if one accounts only for faculty or only for current graduate students? What is the approximate white/non-white ratio of your laboratory and department? Specifically, how does this ratio change if one accounts only for faculty or only for current graduate students? What percentage of students are international vs domestic? What lab funding is available for attending conferences? Is it guaranteed (within reason) that I can attend anywhere I publish a full-length paper? ","date":"2020-08-03","objectID":"/grad_questions.html:3:0","tags":null,"title":"Questions to ask as a prospective graduate student","uri":"/grad_questions.html"},{"categories":null,"content":"Specifically for current graduate students How much do you pay for rent, monthly? Are you sharing a flat with anyone? Have you ever done an internship in a company while working towards your PhD? Did you still get your monthly funding? How did it go? ","date":"2020-08-03","objectID":"/grad_questions.html:4:0","tags":null,"title":"Questions to ask as a prospective graduate student","uri":"/grad_questions.html"},{"categories":null,"content":"I am committed to making the PhD application process more open and clearer to new students, since it is my view that the unnecessary opaqueness of the status quo mostly serves to discourage minorities from applying and to preserve power in the hands of elites. Therefore, I share below the personal statement I used when applying to graduate school in 2018, in hopes it may help someone down the road. I added some comments in square brackets to explain my intended purpose for each section. Of course, it must come with a big disclaimer: I am not in any way claiming that this is a good statement, let alone a model for others’ statements, nor making any promises about your success if you follow this advice. Also, note that the fact that I am posting this online means that this text will appear in an online search, so you probably don’t want to copy specific words or phrases ;) ","date":"2020-08-02","objectID":"/research_statement.html:0:0","tags":null,"title":"My PhD application research statement","uri":"/research_statement.html"},{"categories":null,"content":"Personal Statement To whom it may concern, [This first paragraph is a very brief summary which answers the questions “who am I?”, “what am I applying for?”, “why should you hire me?” The rest of the statement serves as a justification for the pitch made in this paragraph.] My name is Silvia González Sellán and I am a Mathematics and Physics undergraduate student with experience in Computer Graphics research at a high level. I am writing to apply to the direct entry PhD program, to hopefully begin in Fall 2019. I believe my previous achievements can vouch for my ability to proficiently participate in a world-renowned institution like University of Toronto, and I hope my interdisciplinary training can bring to it an innovative perspective. [The next three paragraphs are “background”, and they are not specific to which University I am applying to. Their purpose is to show that I have the experience you’re looking for as a recruiter and I am confortable describing and discussing the details of my research. Also, detailing the specific responsabilities I took on with each project.] By this summer I will be granted two individual Bachelor of Science degrees in both Mathematics and Physics. However, for the past two years I have been dedicating myself mostly to my Computer Graphics research, supervised by professor Alec Jacobson (University of Toronto) and partially funded by several Fields Institute of Mathematics programs. Specifically, I have focused on the subfield of Geometry Processing, working with two or three-dimensional shapes in the form of meshes and using mathematical tools to analyze and manipulate them. In our latest finished project, we circumvented the problem of achieving solid meshes of complex domains by presenting a new way to define discrete differential operators on simpler meshes that make up the final domain via set operations. The applications of our method are manifold, from shape deformations to data smoothing to the computation of solid geodesic distances in a complicated shape. Our work has so far resulted in one high-level publication of which I am the first author, “Solid Geometry Processing on Deconstructed Domains”, which has been accepted with major revisions in the journal Computer Graphics Forum. I have also presented our results in poster format in several venues, like the 2018 Eurographics Symposium on Geometry Processing or the Graphics Interface 2018 conference. Lately, I have begun working on a new project, also supervised by professor Jacobson, involving morphological operations and geometric flows on surfaces, which is still on its early stages but the results of which we intend to submit for publication in Spring 2019. [This ended up happening in Spring 2020!] As the first author and the only student working on these projects for most of their duration, I took on the main responsibilities associated with them: with my supervisor’s assistance, we produced the necessary code and mathematical results and presented them in the most polished way possible, both in poster and paper form. I also worked on satisfying the reviewers’ comments during our first peer-review phase and submitted an improved version of our paper which complied with the major revisions required and is currently under review. [This is the vision section. My intention was to tell the reader “You won’t need to worry about figuring out what to do with me, I have a very clear plan that you should be excited about”.] If given the opportunity of working towards my PhD at University of Toronto, my vision for the program would be two-fold. My most immediate intention is to complete my reading and formal studies in order to achieve a global grasp of Computer Graphics as a field. Attending lectures in different congresses such as SIGGRAPH 2018 has woken me up to the very different avenues one can follow within it, and I would very much love to have a better understanding of these so I can choose my future wisely. Secondly, I would l","date":"2020-08-02","objectID":"/research_statement.html:1:0","tags":null,"title":"My PhD application research statement","uri":"/research_statement.html"},{"categories":null,"content":"The process of applying to graduate school can be overwhelming, especially given how opaque and expensive it can be, especially if you are not from North America. I have been asked for advice many times on this so, while I make it clear I don’t consider myself an expert on this topic nor do I claim to have all the (or, really, any of) the answers, I’ve decided to gather some resources that may help you if you’re thinking about applying: As part of the SIGGRAPH Research Career Development Committee, I am organizing a new mentoring program to help students apply for graduate school positions in Computer Graphics by pairing them with experienced graduate students in our field. If you’re reading this in Fall 2021, you can sign up here. If time has passed as it inexorably does and it is no longer Fall 2021, you can stay up to date on future programs by following our Twitter account. Here’s the research statement I used when I applied in the Fall of 2018. I faced a hard decision on which lab to join for my PhD. Something that really helped with making a choice was asking a consistent set of questions to every prospective advisor. Here they are in case you find them useful. Episodes 101 and onwards of the Podcast Hello PhD make for a good guide on the whole application process, albeit some of their lessons can be limited to the biomedical sciences. My labmate Towaki Takikawa wrote this amazing overview of Graduate School in Canada, which I highly recommend if you’re considering different schools to apply to!. Here’s what MIT EECS professors say they look for in a graduate school application. Makes for a good read! If you are thinking about applying to graduate school and are a member of an underrepresented community in science, do feel free to contact me if you want advice with application strategy or even just chat about life as a PhD student. By the way, if you’re considering different universities to which to apply or aren’t sure where you want to go, I encourage you to try U of T, the best research institution in Canada. So far, my experience has been nothing but positive here. There’s life outside the US! ","date":"2020-08-01","objectID":"/grad_school.html:0:0","tags":null,"title":"Thinking about going to graduate school?","uri":"/grad_school.html"},{"categories":null,"content":"Calling something I have made myself “art” feels pretentious but here is stuff I have done for fun that I am proud of (mostly so I don’t lose track of it myself). An isometric room done following this tutorial by 3DGreenhorn, 2022 Himmelblau ft. Joan Miró, 2021 One in a million chance, 2021 A particularly nice logarithm of a meromorphic function (made with this Matlab script), 2021 The American Dream, 2020 Graphics in the '80s, 2020 ","date":"2019-08-02","objectID":"/art.html:0:0","tags":null,"title":"Art?","uri":"/art.html"},{"categories":null,"content":"Here's a list of all my publications","date":"2019-08-02","objectID":"/publications.html","tags":null,"title":"Publications","uri":"/publications.html"},{"categories":null,"content":" Bayes' Rays: Bayes’ Rays: Uncertainty Quantification for Neural Radiance Fields Lily Goli, Silvia Sellán, Alec Jacobson, Andrea Tagliasacchi 2023 Paper Project Page Code (TBD) Reach for the Spheres: Tangency-Aware Surface Reconstruction of SDFs Silvia Sellán, Christopher Batty, Oded Stein ACM Transactions on Graphics (SIGGRAPH Asia), 2023 Paper Paper (low res) Project Page (TBD) Code (TBD) Constructive Solid Geometry on Neural Signed Distance Fields Zoë Marschner, Silvia Sellán, Hsueh-Ti Derek Liu, Alec Jacobson ACM Transactions on Graphics (SIGGRAPH Asia), 2023 Paper (TBD) Project Page (TBD) Code (TBD) Neural Stochastic Poisson Surface Reconstruction Silvia Sellán, Alec Jacobson ACM Transactions on Graphics (SIGGRAPH Asia), 2023 Paper (TBD) Project Page (TBD) Code (TBD) Stochastic Poisson Surface Reconstruction Silvia Sellán, Alec Jacobson ACM Transactions on Graphics (SIGGRAPH Asia), 2022 Paper Paper (low resolution) Project Page Code Breaking Bad: A Dataset for Geometric Fracture and Reassembly Silvia Sellán*, Yun-Chun Chen*, Ziyi Wu*, Animesh Garg, Alec Jacobson (*joint first authors) Proceedings of Neural Information Processing Systems (NeurIPS) 2022 Featured (previously known as \"Oral\") paper Paper Project Page Breaking Good: Fracture Modes for Realtime Destruction Silvia Sellán, Jack Luong, Leticia Mattos Da Silva, Aravind Ramakrishnan, Yuchuan Yang, Alec Jacobson ACM Transactions on Graphics (to be presented at SIGGRAPH Asia), 2022 Paper Arxiv Code Video Project Page Sex and Gender in the Computer Graphics Research Literature Ana Dodik*, Silvia Sellán*, Theodore Kim, Amanda Phillips (*joint first authors) SIGGRAPH Talk, 2022 Paper Supplement Arxiv ACM Talk Project Page Blender for Academic Papers Silvia Sellán Symposium on Geometry Processing (SGP) Course, 2022 Graphics Interface (GI) Workshop, 2023 Course Swept Volumes via Spacetime Numerical Continuation Silvia Sellán, Noam Aigerman, Alec Jacobson ACM Transactions on Graphics (SIGGRAPH), 2021 Paper Paper (low res) Code Video Talk Project Page Geometry Processing in Matlab using gptoolbox Hsueh-Ti Derek Liu*, Silvia Sellán*, Oded Stein* (*joint first authors) Symposium on Geometry Processing (SGP) Course, 2021 Project Page Video Tutorial Github Tutorial Opening and Closing Surfaces Silvia Sellán, Jacob Kesten, Ang Yan Sheng, Alec Jacobson ACM Transactions on Graphics (SIGGRAPH Asia), 2020 Paper Paper (low res) Code Video Talk Project Page Developability of Heightfields via Rank Minimization Silvia Sellán, Noam Aigerman, Alec Jacobson ACM Transactions on Graphics (SIGGRAPH), 2020 Paper Paper (low res) Code Talk Project Page Solid Geometry Processing on Deconstructed Domains Silvia Sellán, Herng Yi Cheng, Yuming Ma, Mitchell Dembowski, Alec Jacobson Computer Graphics Forum (SGP), 2019 Paper Code Talk Project Page ","date":"2019-08-02","objectID":"/publications.html:0:0","tags":null,"title":"Publications","uri":"/publications.html"},{"categories":null,"content":"Software Gpytoolbox Silvia Sellán, Oded Stein A Python geometry processing toolbox Code Website Botsch-Kobbelt Local Remesher Silvia Sellán A C++ and Python remeshing library Code html and css lifted and adapted from Yotam Gingold, with special thanks to Alec Jacobson. ","date":"2019-08-02","objectID":"/publications.html:1:0","tags":null,"title":"Publications","uri":"/publications.html"},{"categories":null,"content":" sgsellan@cs.toronto.edu www.silviasellan.com Click here to download a pdf version of this CV. ","date":"2019-08-02","objectID":"/cv.html:0:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Education University of Toronto, 2019 - 2024 (expected) PhD in Computer Science Supervisor: Prof. Alec Jacobson University of Oviedo, 2015 - 2019 B.Sc. in Physics University of Oviedo, 2015 - 2019 B.Sc. in Mathematics ","date":"2019-08-02","objectID":"/cv.html:1:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Experience Yale University, 2022 Research Consultant Work carried out with Prof. Theodore Kim Adobe Inc., May 2020 - December 2020 Research Intern Mentored by Noam Aigerman and managed by Jovan Popovic Adobe Inc., July 2019 - October 2019 Research Intern Mentored by Noam Aigerman and managed by Jovan Popovic Fields Institute for Research in the Mathematical Sciences, Summer 2018 Undergraduate Research Intern Supervised by Prof. Alec Jacobson Fields Institute for Research in the Mathematical Sciences, Summer 2017 Undergraduate Research Intern Supervised by Prof. Alec Jacobson ","date":"2019-08-02","objectID":"/cv.html:2:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Journal \u0026 Conference Publications Bayes’ Rays: Uncertainty Quantification for Neural Radiance Fields, 2023 Lily Goli, Cody Reading, Silvia Sellán, Alec Jacobson, Andrea Tagliasacchi TBD Reach For the Spheres: Tangency-aware surface reconstruction of SDFs, 2023 Silvia Sellán, Christopher Batty, Oded Stein ACM Transactions on Graphics (Proc. SIGGRAPH Asia Constructive Solid Geometry on Neural Signed Distance Fields, 2023 Zoë Marschner, Silvia Sellán, Hsueh-Ti Derek Liu, Alec Jacobson ACM Transactions on Graphics (Proc. SIGGRAPH Asia) Neural Stochastic Poisson Surface Reconstruction, 2023 Silvia Sellán, Alec Jacobson ACM Transactions on Graphics (Proc. SIGGRAPH Asia) Stochastic Poisson Surface Reconstruction, 2022 Silvia Sellán, Alec Jacobson ACM Transactions on Graphics (Proc. SIGGRAPH Asia) Breaking Bad: A Dataset for Geometric Fracture and Reassembly, 2022 Silvia Sellán*, Yun-Chun Chen*, Ziyi Wu*, Animesh Garg, Alec Jacobson (*Joint First Authors) Proceedings of Neural Information Processing Systems (NeurIPS) Featured (previously known as “Oral”) paper Breaking Good: Fracture Modes for Realtime Destruction, 2022 Silvia Sellán, Jack Luong, Letticia Mattos Da Silva, Aravind Ramakrishnan, Yuchuan Yang, Alec Jacobson ACM Transactions on Graphics (to be presented at SIGGRAPH Asia) Sex and Gender in the Computer Graphics Research Literature, 2022 Ana Dodik*, Silvia Sellán*, Theodore Kim, Amanda Phillips (*Joint First Authors) SIGGRAPH Talk Swept Volumes via Spacetime Numerical Continuation, 2021 Silvia Sellán, Noam Aigerman, Alec Jacobson ACM Transactions On Graphics (Proc. SIGGRAPH) Opening and Closing Surfaces, 2020 Silvia Sellán, Jacob Kesten, Ang Yan Sheng, Alec Jacobson ACM Transactions On Graphics (Proc. SIGGRAPH Asia) Developability of Heightfields via Rank Minimization, 2020 Silvia Sellán, Noam Aigerman, Alec Jacobson ACM Transactions On Graphics (Proc. SIGGRAPH) Solid Geometry Processing on Deconstructed Domains, 2019 Silvia Sellán, Herng Yi Cheng, Yuming Ma, Mitchell Dembowski, Alec Jacobson Computer Graphics Forum (presented at Eurographics SGP 2019) ","date":"2019-08-02","objectID":"/cv.html:3:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Other Publications Blender for Geometry Processing Academic Papers, 2022 Silvia Sellán Graduate School course presented at Eurographics SGP 2022 Geometry Processing programming in MATLAB with gptoolbox, 2021 Hsueh-Ti Derek Liu*, Silvia Sellán*, Oded Stein* (*Joint First Authors) Graduate School course presented at Eurographics SGP 2021 Efficient and Robust Swept Volumes, 2021 Silvia Sellán, Noam Aigerman, Alec Jacobson Poster presented at the Vector Institute Research Symposium Applications of Geometry Processing to Computer Graphics, 2019 Silvia Sellán B.Sc. in Mathematics thesis supervised by Profs. Alec Jacobson and Carlos Fernández García An introduction to primal inflation, 2019 Silvia Sellán B.Sc. in Physics thesis supervised by Prof. Luigi Toffolati Solid Geometry Processing on Deconstructed Domains, 2018 Silvia Sellán, Herng Yi Cheng, Yuming Ma, Mitchell Dembowski, Alec Jacobson Poster presented at Eurographics SGP 2018 Solving PDEs on Overlapping Domains, 2018 Silvia Sellán, Herng Yi Cheng, Yuming Ma, Mitchell Dembowski, Alec Jacobson Extended abstract published by Review of Undergraduate Computer Science ","date":"2019-08-02","objectID":"/cv.html:4:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Patents Swept Volume Determination Techniques, 2021 Inventors: Silvia Sellán, Noam Aigerman, Alec Jacobson Patent filed by Adobe Inc. Generating Developable Depth Images Using Rank Minimization, 2021 Inventors: Silvia Sellán, Noam Aigerman, Alec Jacobson United States Patent 11080819 ","date":"2019-08-02","objectID":"/cv.html:5:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Software Geometry Processing in Matlab tutorial Author gptoolbox - Geometry Processing Toolbox Contributor gpytoolbox - A Python Geometry Processing Toolbox Author libigl - A Simple C++ Geometry Processing Library Contributor Also, open-source code is available on this website for all journal publications listed above ","date":"2019-08-02","objectID":"/cv.html:6:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Awards and Honours Vanier Canada Doctoral Scholarship, 2021-2024 Natural Sciences and Engineering Research Council of Canada (NSERC) 150,000 CAD award given only to 166 graduate students across all of Canada and across all academic disciplines Beatrice “Trixie” Worsley Graduate Scholarship in Computer Science, 2023 University of Toronto Department of Computer Science 4,000 CAD award given to a student who has taken an active role in promoting the role of women in Computer Science Connaught International Scholarship for Doctoral Students, 2022 University of Toronto Department of Computer Science A 10,000 CAD award designed to assist graduate units in recruiting and supporting top international students Adobe Research Fellowship, 2022 Adobe Research 10,000 USD award given only to ten graduate students worldwide. Dean’s Doctoral Excellence Scholarship, 2021 University of Toronto Faculty of Arts \u0026 Science 25,000 CAD award given one single doctoral students across all Arts \u0026 Science disciplines Connaught International Scholarship for Doctoral Students, 2021 University of Toronto Department of Computer Science A 10,000 CAD award designed to assist graduate units in recruiting and supporting top international students Beatrice “Trixie” Worsley Graduate Scholarship in Computer Science, 2021 University of Toronto Department of Computer Science 4,000 CAD award given to a student who has taken an active role in promoting the role of women in Computer Science Adobe Research Fellowship, 2021 Adobe Research Honorable Mention Connaught International Scholarship for Doctoral Students, 2020 University of Toronto Department of Computer Science A 10,000 CAD award designed to assist graduate units in recruiting and supporting top international students 50th Anniversary Graduate Scholarship, 2020 University of Toronto Department of Computer Science 2,000 CAD Graduate Program Award, 2020 University of Toronto Department of Computer Science 5,000 CAD Program-level Fellowship, 2020 University of Toronto Faculty of Arts \u0026 Science 1,000 CAD Adobe Research Fellowship, 2020 Adobe Research Honorable Mention Connaught International Scholarship for Doctoral Students, 2019 University of Toronto Department of Computer Science A 10,000 CAD award designed to assist graduate units in recruiting and supporting top international students Recognition of Excellence Award, 2019 University of Toronto Department of Computer Science 5,000 CAD Graduate Program Award, 2019 University of Toronto Department of Computer Science 5,000 CAD Program-level Fellowship, 2019 University of Toronto Faculty of Arts \u0026 Science 1,000 CAD Adobe Women-in-Technology Scholarship, 2019 Adobe Inc. Honorable Mention SenseTime Fellowship, 2019 MIT Granted but declined Scholarship for Academic Excellence, 2018 María Cristina Masaveu Peterson Foundation 10,000 EUR Scholarship for Academic Excellence, 2017 María Cristina Masaveu Peterson Foundation 10,000 EUR Scholarship for Academic Excellence, 2016 María Cristina Masaveu Peterson Foundation 10,000 EUR Scholarship for Academic Excellence, 2015 María Cristina Masaveu Peterson Foundation 10,000 EUR Scholarship for Academic Excellence, 2014 María Cristina Masaveu Peterson Foundation 10,000 EUR ","date":"2019-08-02","objectID":"/cv.html:7:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Committee Service CVPR Deep Learning for Geometric Computing, 2023 Organizing committee member ACM SIGGRAPH Women in Graphics Research Community Group, 2022 - Present Executive Comittee Member SIGGRAPH Research Career Development Committee, 2021 - Present Committee member (in undergraduate mentorship subcommittee) Eurographics Symposium on Geometry Processing (SGP), 2023 Session Chair: Representation and Learning Eurographics Symposium on Geometry Processing (SGP), 2023 International Program Committee member Summer Geometry Initiative, 2023 Steering Committee member Women in Graphics Research (WiGRAPH), 2020-2022 Executive Comittee Member CVPR Deep Learning for Geometric Computing, 2022 Organizing committee member ICCV Deep Learning for Geometric Computing, 2021 Program Comittee Member ","date":"2019-08-02","objectID":"/cv.html:8:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Referee Service Eurographics Symposium on Geometry Processing (SGP), 2023 ACM SIGGRAPH Technical Papers, 2023 IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023 The Visual Computer (TVCJ), 2023 Eurographics Technical Papers, 2022 CVPR DLGC Technical Papers, 2022 ACM SIGGRAPH Technical Papers, 2022 ACM SIGGRAPH Posters, 2022 International Symposium on Robotics Research, 2022 Computer Aided Design Journal (CAD-J), 2022 Eurographics Technical Papers, 2021 ACM Transactions on Graphics (ToG), 2021 ICCV DLGC Technical Papers, 2021 Journal of Computer Graphics Techniques (JCGT), 2021 ACM SIGGRAPH Posters, 2021 ","date":"2019-08-02","objectID":"/cv.html:9:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Departmental Service Faculty of Arts and Science Graduate Diversity Working Group, 2022 Invited Member Dean’s Advisory Search Committee - Department Chair, Computer Science, 2021 - 2022 Invited Member DGP Working Group on Fostering a Safe and Inclusive Workplace, 2022 Member DCS Grad program talk for Ukranian undergraduate visiting students, 2022 Panelist Graduate Applications Triager, 2021 16 hours of paid work on processing graduate school applications ","date":"2019-08-02","objectID":"/cv.html:10:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Talks Given “Geometry +”: Uncertain Surface Reconstruction, June 2023 INRIA Nancy, France “Geometry +”: Uncertain Surface Reconstruction, June 2023 INRIA Lyon, France “Geometry +”: Uncertain Surface Reconstruction, June 2023 Adobe Research London, U.K. “Geometry +”: Uncertain Surface Reconstruction, June 2023 UCL London, U.K. “Geometry +”: Uncertain Surface Reconstruction, June 2023 UBC Computer Graphics Seminar hosted by Prof. Alla Sheffer Vancouver, Canada “Geometry +”: Uncertain Surface Reconstruction, June 2023 SFU Computer Vision Seminar hosted by Prof. Andrea Tagliasacchi Vancouver, Canada “Geometry +”: Uncertain Surface Reconstruction, May 2023 EPFL Computer Graphics Seminar hosted by Prof. Mark Pauly Lausanne, Switzerland “Geometry +”: Uncertain Surface Reconstruction, May 2023 University of Milan Computer Graphics Seminar hosted by Prof. Marco Tarini Lausanne, Switzerland “Geometry +”: Uncertain Surface Reconstruction, May 2023 ETH Zürich Computer Graphics Seminar hosted by Prof. Olga Sorkine-Hornung Zürich, Switzerland “Geometry +”: Moving fast, breaking things, and putting them back together, April 2023 University of Southern California Computer Graphics Seminar hosted by Prof. Oded Stein Los Angeles, U.S. “Geometry +”: Uncertain Surface Reconstruction, April 2023 University of Waterloo Computer Graphics Seminar hosted by Prof. Craig Kaplan Waterloo, Canada Uncertain Surface Reconstruction, March 2023 UCLA and CalTech’s Grundfest Memorial Lecture, invited by Profs. Achuta Kadambi and Katie Bowman Virtual Research in Geometry Processing, February 2023 University of Toronto Undergraduate Graphics Club Toronto, Canada “Geometry +”: Moving fast, breaking things and putting them back together, February 2023 Vector Institute Endless Summer School: NeurIPS 2022 Highlights Toronto, Canada Stochastic Poisson Surface Reconstruction, December 2022 SIGGRAPH Asia Technical Papers talk Daegu, South Korea Breaking Good: Fracture Modes for Realtime Destruction, December 2022 SIGGRAPH Asia Technical Papers talk Daegu, South Korea Breaking Bad: A Dataset for Geometric Fracture Reassembly, December 2022 NeurIPS featured (oral) talk New Orleans, U.S. Sex and Gender in the Computer Graphics literature, November 2022 Queer in AI @ NeurIPS workshop New Orleans, U.S. “Geometry +”: Uncertain Surface Reconstruction, November 2022 University of Montreal Computer Graphics Seminar hosted by Prof. Mikhail Bessmeltsev Montreal, Canada “Geometry +”: Moving fast, breaking things and putting them back together, November 2022 Invited talk at Ubisoft La Forge Montreal, Canada “Geometry +”: Moving fast, breaking things and putting them back together, November 2022 McGill University Computer Graphics Seminar hosted by Prof. Paul Kry Montreal, Canada Sex and Gender in the Computer Graphics literature, November 2022 UNC Chapel Hill Computer Vision seminar invited by Professor Roni Sengupta Virtual Virtual Bodies that Matter: A trans researcher’s career in computer graphics, November 2022 Georgewotn University’s Gender, Film and Media Studies seminar, hosted by Prof. Amanda Phillips Washington, D.C., U.S. “Geometry +”: Uncertain Surface Reconstruction, November 2022 John Hopkins University Computer Graphics Seminar hosted by Prof. Misha Kazhdan Baltimore, U.S. “Geometry +”: Uncertain Surface Reconstruction, November 2022 Columbia University Computer Graphics Seminar hosted by Prof. Changxi Zheng New York City, U.S. “Geometry +”: Uncertain Surface Reconstruction, November 2022 NYU Computer Graphics Seminar hosted by Prof. Daniele Panozzo New York City, U.S. “Geometry +”: Uncertain Surface Reconstruction, November 2022 MIT Computer Graphics Seminar hosted by Prof. Justin Solomon Cambridge, U.S. “Geometry +”: Uncertain Surface Reconstruction, November 2022 Inaugural Yale Rising Stars seminar hosted by Prof. Theodore Kim New Haven, U.S. “Geometry +”: Uncertain Surface Reconstruction, November 2022 Dartmouth Computer Graphics Seminar hosted by Prof. Wojciech Ja","date":"2019-08-02","objectID":"/cv.html:11:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"In the news Computer graphics researcher Silvia Sellán is awarded two prestigious scholarships, July 2021 A\u0026S News, written by Chris Sasaki. Archived version. Silvia Sellán on Virtual Colloquium Planning, June 2021 Q \u0026 A with WiGRAPH, written by Kate Salesin. Archived version. ","date":"2019-08-02","objectID":"/cv.html:12:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Organizing ACM SIGGRAPH Women in Graphics Research Community group, 2022 - Present Event Coordinator: Symposium on Geometry Processing. Remote Toronto Geometry Colloquium, 2020 - Present Founder, organizer and art director for a series of talks on Geometry Processing. Toronto, Canada SIGGRAPH Graduate Applications Mentorship Program, 2022 Founder and organizer. Remote Summer Geometry Institute, 2022 Admissions committee member and session planning. Remote CVPR Deep Learning for Geometric Computing, 2022 Organizing committee member Women in Graphics Research, 2020 - 2022 Event Coordinator: Symposium on Geometry Processing. Remote SIGGRAPH Graduate Applications Mentorship Program, 2021 Founder and organizer. Remote Summer Geometry Institute, 2021 Admissions committee member and session planning. Remote Symposium on Geometry Processing (SGP), 2021 Student volunteer working on tech support full time during the conference and in Spanish-language outreach Remote Toronto-Montreal-Waterloo Graphics Workshop (TomatoGRAPH), 2021 Student volunteer Toronto, Canada ","date":"2019-08-02","objectID":"/cv.html:13:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Teaching Summer Geometry Institute, Summer 2022 Instructor of a full-day tutorial including lectures, coding demos and exercises. Under the supervision of Professor Justin Solomon, MIT Symposium on Geometry Processing (SGP), Summer 2022 Lecturer of the SGP graduate school course Blender for Academic Papers Summer Geometry Institute, Summer 2021 Instructor of a full-day tutorial including lectures, coding demos and exercises. Under the supervision of Professor Justin Solomon, MIT Symposium on Geometry Processing (SGP), Summer 2021 Co-lecturer of the SGP graduate school course An introduction to geometry processing programming in MATLAB with gptoolbox CSC165: Mathematical Expression and Reasoning for Computer Science, Winter 2020 Teaching Assistant (120 hours) Professor David Liu Individual High School Tutoring, 2015-2018 Weekly paid mathematics and physics tutoring ","date":"2019-08-02","objectID":"/cv.html:14:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Anonymous teaching feedback Summer Geometry Institute During the summer of 2021, I planned, prepared and conducted a 6-hour long tutorial session on the topic of shape representations for undergraduate students of underrepresented communities, as part of MIT’s Summer Geometry Institute (SGI). A representative sample of the anonymous feedback collected by professor Justin Solomon is reproduced below, each paragraph corresponding to different student: Silvia Sellán’s presentation was idyllic, it gave the feeling of being a duck in a pond being fed delicious crumbs of bread, the students being the duck and Silvia the feeder throwing in one after another the information that we like the ducks devoured. The presentation itself was amazing to go beyond analogy it was clear and concise towards learning the topic, the information did not feel too overwhelming, nor too brief. The exercises as well as giving focus upon them and breaking them apart into which to do at what times, they felt like the perfect amount of material in order to have us learn and test our knowledge of the topics. I just wanted to say that I really enjoyed Silvia’s programme. Cutting out all the formulas definitely made her material really accessible and easy to follow without worrying about the precise details of what is going on. I think leaving these details for us to figure out by doing the exercises is really good for developing understanding, rather than having a perhaps more technical talk which is harder to follow and then not quite knowing how to approach the exercises. Silvia’s lecture was the easiest to follow and the most approachable. Silvia’s tutorial: Lively and engaging, I liked how a narrative that tied in everything together neatly was presented. I really liked Silvia Sellan’s tutorial day because for the presentations she gave us a story illustrating the motivation behind the concepts and theory and the actual coding assignments were very accessible and did not require a lot of background material. I think a very good example of this was Silvia Sellan’s tutorial day. She approached the advanced topics from a big picture perspective and all of the coding exercises needed “basic” MATLAB and knowledge of calculus and a small amount of linear algebra. I thoroughly enjoyed Silvia’s talk and the associated exercises. I also found Silvia’s talk very valuable, not only for the geometry processing material offered (which was undoubtedly great, well-structured and very accessible), but also for increasing our awareness about potential nefarious uses of geometry processing. Also the brief digressions on true diversity when talking about fonts/letters were in my opinion very welcome – I (unfortunately) tend to think in a very ““westernized”” way, and it’s always good to bring awareness to things outside of our intellectual comfort zone. I really liked Silvia Sellán’s day of the tutorial week. I think she did a really good job of creating presentations and exercises that met me where I am as a student without a formal experience in geometry processing. The mathematics and computer science that she talked as well as exercises she designed were accessible to me as someone who has undergraduate majors in mathematics and computer science as well as had participated in larger projects with programming computer graphics components. I also think she did a really good job of telling and motivating a story, which was really important to staying engaged throughout the day. I also really appreciate that she spoke about ethics in computing and the need to think critically about academic work. It’s definitely something that is not spoken enough about and that needs to be spoken about more. YOU GUYS ARE WONDERFUL! Not gonna lie, I started looking at PhD opportunities to pursue this field after attending this program. ","date":"2019-08-02","objectID":"/cv.html:15:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Mentoring Graduate School Applications, 2020 - Present Volunteer mentoring of dozens of prospective Computer Graphics students from underrepresented groups with their graduate school application package and decisions. Successful applicant destinations include MIT, UCSD, University of Toronto, UBC and others. Remote Canada-Wide Science Fair, Spring 2022 Mentored two grade 11 students with their Science Fair project as part of UofT’s Pursue STEM Toronto, Canada Canadian Black Scientists Network Youth Science Fair, Winter 2022 Mentored two grade 11 students with their Science Fair project as part of UofT’s Pursue STEM Toronto, Canada University of Toronto DCS Graduate Applications Mentorship Program, Fall 2021 Mentor for several prospective graduate students. Toronto, Canada SIGGRAPH Graduate Applications Mentorship Program, Fall 2021 Mentor for several prospective graduate students Virtual Fields Undergraduate Summer Research Program, Summer 2021 Graduate research mentor for a group of four undergraduate researchers. Toronto, Canada Creating a better summer experience: A DEI workshop, Spring 2021 Certified participation in DEI workshop for mentors of undergraduate students organized by the Center for Minorities in the Mathematical Sciences. Virtual Fields Undergraduate Summer Research Program 2020 - 2021 Graduate research mentor for a group of four undergraduate researchers. Toronto, Canada ","date":"2019-08-02","objectID":"/cv.html:16:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Anonymous mentoring feedback Summer Geometry Institute During the summer of 2021, I worked as a volunteer mentor for undergraduate students of underrepresented communities, as part of MIT’s Summer Geometry Institute. A representative sample of the anonymous feedback about my mentoring collected by professor Justin Solomon is reproduced below, each quotation corresponding to different student: I still have no idea what Silvia’s role was, but she went above and beyond to help out with everything. She made us all feel welcome in the Slack channel before SGI even started and continued to dole out advice and support throughout the whole of SGI. She also patiently answered my millions of questions almost as quickly as I could ask them. Silvia ensured we all felt welcome right from the beginning of the Slack channel. When we introduced ourselves, I noticed she found something nice to say to each of us, and it felt very welcoming to have that display of friendliness right from the get-go. Silvia Sellán, I would like to thank you specifically for the SGP \u0026 Siggraph 2021 wiggraph event, sharing your thoughts in grad school event and being accessible. ","date":"2019-08-02","objectID":"/cv.html:17:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"},{"categories":null,"content":"Non-academic Volunteering Reading Partners August 2020 Translation of documents into Spanish for literacy non-profit United States General election worker April 2019 Day-long volunteer helping citizens vote on the day of the Spanish General Elections. Spain General election worker June 2016 Day-long volunteer helping citizens vote on the day of the Spanish General Elections. Spain ","date":"2019-08-02","objectID":"/cv.html:18:0","tags":null,"title":"Silvia Sellán - Curriculum Vitae","uri":"/cv.html"}]